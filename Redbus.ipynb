{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install mysql-connector-python pandas streamlit google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver import ActionChains\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrolling to the bottom to load all content\n",
    "def scrolldown():\n",
    "    scrolling = True\n",
    "    while scrolling:\n",
    "        old_page_source = driver.page_source\n",
    "        body = driver.find_element(By.TAG_NAME, \"body\")\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(2)\n",
    "        new_page_source = driver.page_source\n",
    "        if new_page_source == old_page_source:\n",
    "            scrolling = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GETTING ROUTE NAMES AND ROUTE_LINKS\n",
    "\n",
    "def route_name_link(link):\n",
    "\n",
    "   driver = webdriver.Chrome()\n",
    "   wait = WebDriverWait(driver, 10)\n",
    "   driver.get(link)\n",
    "   driver.implicitly_wait(3)    \n",
    "   route_and_link=[]\n",
    "\n",
    "   pc = wait.until(EC.presence_of_element_located((By.XPATH, \"//*[@class='DC_117_paginationTable']\")))\n",
    "   num_pgs =len(driver.find_elements(By.CLASS_NAME, \"DC_117_pageTabs \"))+1\n",
    "   if num_pgs==1:\n",
    "      #getting bus routes names\n",
    "      Bus_routes=driver.find_elements(By.XPATH,\"//a[@class='route']\")\n",
    "      allroute=[i.text for i in Bus_routes]\n",
    "      \n",
    "      #getting bus_routes_links\n",
    "      nested_div = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.D117_main.D117_container')))\n",
    "      route_links = nested_div.find_elements(By.CSS_SELECTOR, 'div.route_link')\n",
    "      link=[i.find_element(By.TAG_NAME,\"a\").get_attribute('href') for i in route_links]\n",
    "      \n",
    "      r=zip(allroute,link)\n",
    "      route_and_link.extend(r)\n",
    "   else:\n",
    "      for i in range(1,num_pgs):\n",
    "         #getting bus routes names\n",
    "         Bus_routes=driver.find_elements(By.XPATH,\"//a[@class='route']\")\n",
    "         allroute=[i.text for i in Bus_routes]  \n",
    "         \n",
    "         #getting bus_routes_links\n",
    "         nested_div = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.D117_main.D117_container')))\n",
    "         route_links = nested_div.find_elements(By.CSS_SELECTOR, 'div.route_link')\n",
    "         link=[i.find_element(By.TAG_NAME,\"a\").get_attribute('href') for i in route_links]\n",
    "         \n",
    "         r=zip(allroute,link)\n",
    "         route_and_link.extend(r)\n",
    "         \n",
    "         if i==num_pgs-1:\n",
    "            break\n",
    "         else:\n",
    "            next_page= pc.find_element(By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{i+ 1}\"]')\n",
    "            action = ActionChains(driver)\n",
    "            action.move_to_element(next_page).perform()\n",
    "            time.sleep(2)\n",
    "            next_page.click()\n",
    "            time.sleep(3)\n",
    "      \n",
    "   return route_and_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "\n",
    "def route_name_link(link):\n",
    "    # Initialize WebDriver\n",
    "    driver = webdriver.Chrome()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    driver.get(link)\n",
    "    driver.implicitly_wait(3)\n",
    "    route_and_link = []\n",
    "\n",
    "    try:\n",
    "        # Wait for the pagination table to load\n",
    "        pagination_table = wait.until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//div[@class=\"DC_117_paginationTable\"]'))\n",
    "        )\n",
    "\n",
    "        # Calculate the number of pages\n",
    "        num_pgs = len(driver.find_elements(By.CLASS_NAME, \"DC_117_pageTabs\")) + 1\n",
    "\n",
    "        for page in range(1, num_pgs + 1):\n",
    "            # Get bus route names\n",
    "            bus_routes = driver.find_elements(By.XPATH, \"//a[@class='route']\")\n",
    "            all_routes = [route.text for route in bus_routes]\n",
    "\n",
    "            # Get bus route links\n",
    "            nested_div = wait.until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, 'div.D117_main.D117_container'))\n",
    "            )\n",
    "            route_links = nested_div.find_elements(By.CSS_SELECTOR, 'div.route_link')\n",
    "            links = [link.find_element(By.TAG_NAME, \"a\").get_attribute('href') for link in route_links]\n",
    "\n",
    "            # Combine names and links\n",
    "            route_and_link.extend(zip(all_routes, links))\n",
    "\n",
    "            # Navigate to the next page if more pages exist\n",
    "            if page < num_pgs:\n",
    "                next_page = pagination_table.find_element(\n",
    "                    By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{page + 1}\"]'\n",
    "                )\n",
    "                ActionChains(driver).move_to_element(next_page).perform()\n",
    "                time.sleep(2)\n",
    "                next_page.click()\n",
    "                time.sleep(3)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        # Close the WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "    return route_and_link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click view buses\n",
    "def click_view_buses():\n",
    "    try:\n",
    "        # Locate and click the 'View Buses' button if needed\n",
    "            view_buses_button = wait.until(EC.presence_of_all_elements_located((By.XPATH, \"//div[@class='button']\")))\n",
    "            #print(\"len()\", len(view_buses_button))\n",
    "            for i in range(len(view_buses_button)-1,-1,-1):\n",
    "                view_buses_button[i].click()\n",
    "                time.sleep(2)\n",
    "    except:\n",
    "            pass\n",
    "            for view_buses in view_buses_button:\n",
    "                try:\n",
    "                    view_buses.click()\n",
    "                    scrolling = True\n",
    "                    while scrolling:\n",
    "                        old_page_source = driver.page_source\n",
    "                        body = driver.find_element(By.TAG_NAME, \"body\")\n",
    "                        body.send_keys(Keys.PAGE_DOWN)\n",
    "                        time.sleep(2)\n",
    "                        new_page_source = driver.page_source\n",
    "                        if new_page_source == old_page_source:\n",
    "                            scrolling = False\n",
    "                    time.sleep(5)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting bus details\n",
    "\n",
    "def get_bus(link):\n",
    "    driver.get(link)\n",
    "    time.sleep(2)\n",
    "    click_view_buses()\n",
    "    #scrolldown()\n",
    "    b=driver.find_elements(By.CSS_SELECTOR,\"div[class='button']\")\n",
    "    for i in range(len(b)-1,-1,-1):\n",
    "        try:\n",
    "            b[i].click()\n",
    "        except:\n",
    "            print()\n",
    "    x=0\n",
    "    l=[]\n",
    "    while True:\n",
    "        x=x+1\n",
    "        driver.execute_script('scrollBy(0,100)')\n",
    "        #time.sleep(0.5)\n",
    "        if(x>1000):\n",
    "            break\n",
    "    details = []\n",
    "    bus_containers = wait.until(EC.presence_of_all_elements_located((By.XPATH, \"//div[contains(@class, 'clearfix bus-item')]\")))\n",
    "    for bus_container in bus_containers:\n",
    "        try:\n",
    "            \n",
    "            #routes_name = bus_container.find_element(By.XPATH, \".//div[@class='D136_h1']\").text\n",
    "            busname = bus_container.find_element(By.XPATH, \".//div[@class='travels lh-24 f-bold d-color']\").text\n",
    "            bustype = bus_container.find_element(By.XPATH, \".//div[@class='bus-type f-12 m-top-16 l-color evBus']\").text\n",
    "            departuretiming = bus_container.find_element(By.XPATH, \".//div[@class='dp-time f-19 d-color f-bold']\").text\n",
    "            duration = bus_container.find_element(By.XPATH, \".//div[@class='dur l-color lh-24']\").text\n",
    "            reachtiming = bus_container.find_element(By.XPATH, \".//div[@class='bp-time f-19 d-color disp-Inline']\").text\n",
    "            rating = bus_container.find_element(By.XPATH, \".//div[@class='rating-sec lh-24']\").text\n",
    "            price = bus_container.find_element(By.XPATH, \".//div[@class='fare d-block']\").text\n",
    "            seat = bus_container.find_element(By.XPATH, \".//div[@class='column-eight w-15 fl']\").text\n",
    "\n",
    "            details.append({\n",
    "                'links':link,\n",
    "                #'Route_name': routes_name,\n",
    "                'Bus_name': busname,\n",
    "                'Bus_type': bustype,\n",
    "                'Departure_time': departuretiming,\n",
    "                'Duration': duration,\n",
    "                'Arrival_time': reachtiming,\n",
    "                'Ratings': rating,\n",
    "                'Prices': price,\n",
    "                'Seat_availability': seat,\n",
    "            })\n",
    "        except:\n",
    "            pass     \n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(nested_list):\n",
    "    \"\"\"Flattens a nested list.\"\"\"\n",
    "    return [item for sublist in nested_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get all states data in Redbus\n",
    "def all_state(state_link): \n",
    "    name_rlink= route_name_link(state_link)\n",
    "    driver = webdriver.Chrome()\n",
    "    route_link=[i[1] for i in name_rlink]\n",
    "\n",
    "    all_data=[]\n",
    "    for link in route_link:\n",
    "        try:\n",
    "            all_data.append(get_bus(link))\n",
    "            driver = webdriver.Chrome()\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "\n",
    "# Flattening the collected data\n",
    "    flattened_data = flatten_list(all_data)\n",
    "    df=pd.DataFrame(flattened_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Step 1: Initialize the WebDriver (e.g., for Chrome)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Step 2: Open the webpage\n",
    "driver.get('https://www.redbus.in/')  # Replace with your target URL\n",
    "\n",
    "try:\n",
    "    # Step 3: Wait for the element to be clickable\n",
    "    element = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, 'your_xpath_here')))  # Replace with your XPath\n",
    "    element.click()\n",
    "    print(\"Element clicked successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    # Step 4: Close the browser\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Close a popup if it exists\n",
    "try:\n",
    "    popup_close_button = driver.find_element(By.XPATH, 'popup_close_button_xpath')\n",
    "    popup_close_button.click()\n",
    "except:\n",
    "    print(\"No popup found or could not close it.\")\n",
    "\n",
    "# Now click the target element\n",
    "element = driver.find_element(By.XPATH, 'your_xpath_here')\n",
    "element.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main code\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 10)\n",
    "action = ActionChains(driver)\n",
    "\n",
    "AP_data =all_state('https://www.redbus.in/online-booking/apsrtc/?utm_source=rtchometile')\n",
    "Kerala_data=all_state('https://www.redbus.in/online-booking/ksrtc-kerala/?utm_source=rtchometile')\n",
    "jammukashmir_data=all_state('https://www.redbus.in/online-booking/jksrtc')\n",
    "punjab_data=all_state('https://www.redbus.in/online-booking/pepsu/?utm_source=rtchometile')\n",
    "Rajasthan_data=all_state('https://www.redbus.in/online-booking/rsrtc/?utm_source=rtchometile')\n",
    "Telangana_data=all_state('https://www.redbus.in/online-booking/tsrtc/?utm_source=rtchometile')\n",
    "West_bengal_data=all_state('https://www.redbus.in/online-booking/west-bengal-transport-corporation?utm_source=rtch')\n",
    "karbi_anglong_data=all_state('https://www.redbus.in/online-booking/kaac-transport')\n",
    "Kadamba_data= all_state('https://www.redbus.in/online-booking/ktcl/?utm_source=rtchometile')\n",
    "Bihar_data=all_state('https://www.redbus.in/online-booking/bihar-state-road-transport-corporation-bsrtc/?utm_source=rtchometile')\n",
    "\n",
    "#splitting route from links\n",
    "AP_data_df = AP_data\n",
    "AP_data_df['route'] = AP_data['links'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "Kerala_data_df = Kerala_data\n",
    "Kerala_data_df['route'] = Kerala_data['links'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "jammukashmir_data_df=jammukashmir_data\n",
    "jammukashmir_data_df['route'] = jammukashmir_data['links'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "punjab_data_df=punjab_data\n",
    "punjab_data_df['route'] = punjab_data['links'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "Rajasthan_data_df=Rajasthan_data\n",
    "Rajasthan_data_df['route'] = Rajasthan_data['links'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "Telangana_data_df=Telangana_data\n",
    "Telangana_data_df['route'] = Telangana_data['links'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "West_bengal_data_df=West_bengal_data\n",
    "West_bengal_data_df['route'] = West_bengal_data['links'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "karbi_anglong_data_df=karbi_anglong_data\n",
    "karbi_anglong_data_df['route'] = karbi_anglong_data['links'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "Kadamba_data_df=Kadamba_data\n",
    "Kadamba_data_df['route'] = Kadamba_data['links'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "Bihar_data_df=Bihar_data\n",
    "Bihar_data_df['route'] = Bihar_data['links'].apply(lambda x: x.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the directory path\n",
    "directory = r'C:\\Users\\ADMIN\\OneDrive\\Desktop\\OneDrive\\Documents\\Redbus'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# List of file names and corresponding data\n",
    "csv_files = {\n",
    "    'ap_data.csv': {'Column1': [1, 2, 3], 'Column2': ['A', 'B', 'C']},\n",
    "    'Bihar_data.csv': {'Column1': [4, 5, 6], 'Column2': ['D', 'E', 'F']},\n",
    "    'jammukashmir_data.csv': {'Column1': [7, 8, 9], 'Column2': ['G', 'H', 'I']},\n",
    "    'Kadamba_data.csv': {'Column1': [10, 11, 12], 'Column2': ['J', 'K', 'L']},\n",
    "    'Karbi_Anglong_data.csv': {'Column1': [13, 14, 15], 'Column2': ['M', 'N', 'O']},\n",
    "    'Kerala_data.csv': {'Column1': [16, 17, 18], 'Column2': ['P', 'Q', 'R']},\n",
    "    'Punjab_data.csv': {'Column1': [19, 20, 21], 'Column2': ['S', 'T', 'U']},\n",
    "    'Rajasthan_data.csv': {'Column1': [22, 23, 24], 'Column2': ['V', 'W', 'X']},\n",
    "    'Telangana_data.csv': {'Column1': [25, 26, 27], 'Column2': ['Y', 'Z', 'AA']},\n",
    "    'westbengal_data.csv': {'Column1': [28, 29, 30], 'Column2': ['AB', 'AC', 'AD']}\n",
    "}\n",
    "\n",
    "# Loop through the dictionary and create CSV files\n",
    "for file_name, data in csv_files.items():\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Define the full file path\n",
    "    file_path = os.path.join(directory, file_name)\n",
    "    \n",
    "    # Save the DataFrame as a CSV file\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Created {file_path}\")\n",
    "\n",
    "print(\"All CSV files have been created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas sqlalchemy pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# MySQL credentials\n",
    "mysql_user = 'root'\n",
    "mysql_password = '1234'\n",
    "mysql_host = '127.0.0.1'\n",
    "mysql_port = '3306'\n",
    "mysql_database = 'redbus'\n",
    "\n",
    "# Create a connection to MySQL database\n",
    "engine = create_engine(f'mysql+pymysql://{mysql_user}:{mysql_password}@{mysql_host}:{mysql_port}/{mysql_database}', echo=True)\n",
    "\n",
    "# List of CSV file paths\n",
    "csv_files =[\n",
    "    'C:\\\\Users\\\\ADMIN\\\\OneDrive\\\\Desktop\\\\OneDrive\\\\Documents\\\\Redbus\\\\ap_data.csv', \n",
    "    'C:\\\\Users\\\\ADMIN\\\\OneDrive\\\\Desktop\\\\OneDrive\\\\Documents\\\\Redbus\\\\Bihar_data.csv', \n",
    "    'C:\\\\Users\\\\ADMIN\\\\OneDrive\\\\Desktop\\\\OneDrive\\\\Documents\\\\Redbus\\\\jammukashmir_data.csv', \n",
    "    'C:\\\\Users\\\\ADMIN\\\\OneDrive\\\\Desktop\\\\OneDrive\\\\Documents\\\\Redbus\\\\Kadamba_data.csv', \n",
    "    'C:\\\\Users\\\\ADMIN\\\\OneDrive\\\\Desktop\\\\OneDrive\\\\Documents\\\\Redbus\\\\Karbi_Anglong_data.csv',\n",
    "    'C:\\\\Users\\\\ADMIN\\\\OneDrive\\\\Desktop\\\\OneDrive\\\\Documents\\\\Redbus\\\\Kerala_data.csv', \n",
    "    'C:\\\\Users\\\\ADMIN\\\\OneDrive\\\\Desktop\\\\OneDrive\\\\Documents\\\\Redbus\\\\Punjab_data.csv',\n",
    "    'C:\\\\Users\\\\ADMIN\\\\OneDrive\\\\Desktop\\\\OneDrive\\\\Documents\\\\Redbus\\\\Rajasthan_data.csv',\n",
    "    'C:\\\\Users\\\\ADMIN\\\\OneDrive\\\\Desktop\\\\OneDrive\\\\Documents\\\\Redbus\\\\Telangana_data.csv',\n",
    "    'C:\\\\Users\\\\ADMIN\\\\OneDrive\\\\Desktop\\\\OneDrive\\\\Documents\\\\Redbus\\\\westbengal_data.csv'\n",
    "]\n",
    "\n",
    "# List to hold DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop through the list of CSV files\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        # Attempt to read the CSV file\n",
    "        df = pd.read_csv(file)\n",
    "        # Append the DataFrame to the list if successful\n",
    "        dataframes.append(df)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Warning: {file} is empty and has been skipped.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Could not read {file} due to {e}\")\n",
    "\n",
    "# Concatenate all valid DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv('combined_file.csv', index=False)\n",
    "\n",
    "# Create a connection to MySQL database\n",
    "engine = create_engine(f'mysql+pymysql://{mysql_user}:{mysql_password}@{mysql_host}:{mysql_port}/{mysql_database}', echo=True)\n",
    "\n",
    "#load the datasets int sql\n",
    "combined_df.to_sql('combined', con=engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Streamlit app\n",
    "st.set_page_config(page_title=\"Redbus Data Scraping\", layout=\"wide\")\n",
    "st.title(\":bus: :orange[**Redbus Data Scraping with Selenium & Dynamic Filtering**]\")\n",
    "\n",
    "# Sidebar with project information\n",
    "with st.sidebar: \n",
    "    st.markdown(\"### :green_book: :green[**About**]\")\n",
    "    st.markdown('''\n",
    "    This project aims to streamline the collection and analysis of bus travel data.\n",
    "    Using **:blue[Selenium]** for automated data extraction from Redbus, it gathers details like routes, schedules, prices, and seat availability.\n",
    "    This initiative helps improve operational efficiency and strategic planning in the transportation industry.\n",
    "    ''')\n",
    "    # Additional notes or instructions\n",
    "    st.markdown(\"### :memo: :green[**Additional Notes**]\")\n",
    "    st.markdown(\"For more details, please refer to the [Redbus website](https://www.redbus.in).\")\n",
    "\n",
    "\n",
    "# MySQL credentials\n",
    "mysql_user = 'root'\n",
    "mysql_password = '1234'\n",
    "mysql_host = '127.0.0.1'\n",
    "mysql_port = '3306'\n",
    "mysql_database = 'redbus'\n",
    "\n",
    "# Create a connection to the MySQL database\n",
    "engine = create_engine(f'mysql+pymysql://{mysql_user}:{mysql_password}@{mysql_host}:{mysql_port}/{mysql_database}')\n",
    "\n",
    "# Fetch data from the database\n",
    "q1 = '''SELECT * FROM redbus_table'''\n",
    "df_all = pd.read_sql(q1, engine)\n",
    "\n",
    "# Main content layout\n",
    "# st.markdown(\"### **:orange[Filter Options]**\")\n",
    "with st.container():\n",
    "    col1, col2, col3 = st.columns(3)\n",
    "\n",
    "    # Route filter \n",
    "    with col1:\n",
    "        route_options = df_all['route'].unique()\n",
    "        selected_route = st.selectbox('Select a Route:', route_options, index=None, placeholder='select a route')\n",
    "\n",
    "    # Bus type filter\n",
    "    q2 = '''SELECT * FROM redbus_table WHERE route = %s'''\n",
    "    df_route = pd.read_sql(q2, engine, params=(selected_route,))\n",
    "    with col2:\n",
    "        bustype_options = df_route['Bus_type'].unique()\n",
    "        selected_bustype = st.selectbox('Select a Bus Type:', bustype_options, index=None, placeholder='select a bustype')\n",
    "\n",
    "    # Price filter\n",
    "    q3 = '''SELECT * FROM redbus_table WHERE route = %s AND Bus_type = %s'''\n",
    "    df_filtered = pd.read_sql(q3, engine, params=(selected_route, selected_bustype))\n",
    "    with col3:\n",
    "        price_options = df_filtered['Prices'].unique()\n",
    "        selected_price = st.selectbox('Select a Price Range:', price_options, index=None, placeholder='select a price')\n",
    "\n",
    "# Search button\n",
    "if st.button('Search'):\n",
    "    # Display filtered data\n",
    "    st.markdown(\"### **:green[Filtered Bus Data]**\")\n",
    "    st.markdown(f\"**Displaying data for:** *{selected_route}*, *{selected_bustype}*, *{selected_price}*\")\n",
    "    st.dataframe(df_filtered)\n",
    "\n",
    "    # Download button for filtered data\n",
    "    csv = df_filtered.to_csv(index=False)\n",
    "    st.download_button(\n",
    "        label=\"Download Filtered Data as CSV\",\n",
    "        data=csv,\n",
    "        file_name='filtered_redbus_data.csv',\n",
    "        mime='text/csv',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
